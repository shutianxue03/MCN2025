{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec2d61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Required environment: Python 3.10 or more\n",
    "\n",
    "# # üß∞ Install required packages (run this cell only once per environment setup)\n",
    "# # Install the core IBL tools: ONE-api (data access), ibllib (IBL tools),\n",
    "# !pip install ONE-api ibllib \n",
    "\n",
    "# # Install brainbox (analysis utilities)\n",
    "# !pip install git+https://github.com/int-brain-lab/ibllib.git\n",
    "\n",
    "# # Install the scientific and plotting libraries\n",
    "# !pip install matplotlib seaborn pandas numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "17f52b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/xueshutian/Downloads/ONE/openalyx.internationalbrainlab.org\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import scipy.io as sio  # For saving\n",
    "\n",
    "# For clearing cache\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "from one.api import ONE\n",
    "from brainbox.io.one import SpikeSortingLoader, SessionLoader\n",
    "from brainbox.behavior.training import compute_performance\n",
    "from brainbox.population.decode import get_spike_counts_in_bins\n",
    "\n",
    "# Connect to IBL data server\n",
    "one = ONE(base_url='https://openalyx.internationalbrainlab.org')\n",
    "print(one.cache_dir)\n",
    "\n",
    "# =========================================\n",
    "# üîÅ Loop through contrast √ó prior settings\n",
    "# =========================================\n",
    "# Spike count window settings\n",
    "window_start = 0          # in seconds\n",
    "window_end = 300 / 1000   # in seconds\n",
    "\n",
    "# nNeurons_lb = 10\n",
    "nTrials_lb = 2 # Minimum number of trials\n",
    "RT_ub = 2000 # trials with RT more than this dur (in ms) will be removed\n",
    "\n",
    "# Identify eid (id for experiment)\n",
    "eid = '28741f91-c837-4147-939e-918d38d849f2' # Churchlandlab\n",
    "label = 'probe00'\n",
    "target_region = 'CP'\n",
    "flag_good_quality = False # False: do no do quality control\n",
    "prior = .5 # no bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54e86016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid: bf591043-03c2-48bb-9197-e17e85aaeb8f, labels: probe00\n",
      "pid: 5458cb27-d065-4626-bcd8-1aa775e1115e, labels: probe01\n"
     ]
    }
   ],
   "source": [
    "# --- Load session ---\n",
    "session_info = one.get_details(eid)\n",
    "\n",
    "# Identify the corresponding eid (id for experiment)\n",
    "pids, labels = one.eid2pid(eid)\n",
    "\n",
    "for pid, pname in zip(pids, labels):\n",
    "  print(f'pid: {pid}, labels: {pname}')\n",
    "\n",
    "trials = one.load_object(eid, 'trials', collection='alf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7aaaac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==== SESSION LOADED ====\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Load trial and probe info\n",
    "# ================================\n",
    "pids, labels = one.eid2pid(eid)\n",
    "trials = one.load_object(eid, 'trials', collection='alf')\n",
    "contrast_levels = np.unique(trials['contrastLeft'])\n",
    "prior_levels = np.unique(trials['probabilityLeft'])\n",
    "\n",
    "# assert that prior_levels has three levels: 0.2, 0.5 and 0.8\n",
    "assert np.array_equal(prior_levels, [0.2, 0.5, 0.8]), f\"Unexpected prior_levels: {prior_levels}\"\n",
    "\n",
    "# ================================\n",
    "# Load spikes and clusters\n",
    "# ================================\n",
    "ssl = SpikeSortingLoader(eid=eid, one=one, pname=label)\n",
    "spikes, clusters, channels = ssl.load_spike_sorting()\n",
    "clusters = ssl.merge_clusters(spikes, clusters, channels)\n",
    "\n",
    "print(' ==== SESSION LOADED ====')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7231a9f",
   "metadata": {},
   "source": [
    "## Save respNeural and respBehav to .mat files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b1b2af8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1 -1 -1  1  1 -1 -1  1  1]\n",
      "  ‚úÖ Stored contrast 0.0 | Trials: 10\n",
      "[ 1 -1  1  1  1  1 -1 -1 -1 -1 -1  1  1 -1 -1 -1  1  1  1 -1]\n",
      "  ‚úÖ Stored contrast 0.0625 | Trials: 20\n",
      "[ 1  1  1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1  1  1  1 -1 -1 -1]\n",
      "  ‚úÖ Stored contrast 0.125 | Trials: 20\n",
      "[-1  1 -1  1  1 -1 -1  1 -1 -1  1 -1  1  1  1  1 -1 -1 -1  1]\n",
      "  ‚úÖ Stored contrast 0.25 | Trials: 20\n",
      "[-1  1  1 -1 -1 -1  1  1  1 -1 -1 -1  1 -1 -1  1  1  1  1 -1]\n",
      "  ‚úÖ Stored contrast 1.0 | Trials: 20\n",
      "[]\n",
      "  ‚úÖ Stored contrast nan | Trials: 0\n"
     ]
    }
   ],
   "source": [
    "# Preallocate \n",
    "respNeural = []  # List to store spike counts\n",
    "respBehav = []  # List to store behavioral data\n",
    "\n",
    "# =========================\n",
    "# üîÅ Loop over contrasts\n",
    "# =========================\n",
    "for contrast in contrast_levels:\n",
    "    \n",
    "    # -------------------------\n",
    "    # üß™ Trial selection\n",
    "    # -------------------------\n",
    "    trial_mask = ((trials['contrastLeft'] == contrast) | (trials['contrastRight'] == contrast)) & \\\n",
    "                (trials['probabilityLeft'] == prior) \n",
    "    valid_trial_times = trials['stimOn_times'][trial_mask]\n",
    "\n",
    "    # if len(valid_trial_times) < nTrials_lb:\n",
    "    #     continue\n",
    "\n",
    "    # -------------------------\n",
    "    # ‚è±Ô∏è Define time bins per trial\n",
    "    # -------------------------\n",
    "    time_bins = np.stack([\n",
    "        valid_trial_times + window_start,\n",
    "        valid_trial_times + window_end\n",
    "    ], axis=1)\n",
    "\n",
    "    # -------------------------\n",
    "    # üîç Spike filtering\n",
    "    # -------------------------\n",
    "    is_valid_spike = np.isin(spikes['clusters'], valid_cluster_ids)\n",
    "    spike_times = spikes['times'][is_valid_spike]\n",
    "    spike_clusters = spikes['clusters'][is_valid_spike]\n",
    "\n",
    "    # -------------------------\n",
    "    # üìä Spike count matrix\n",
    "    # -------------------------\n",
    "    spike_counts, used_cluster_ids = get_spike_counts_in_bins(\n",
    "        spike_times, spike_clusters, time_bins\n",
    "    )  # Output: (n_trials x n_neurons)\n",
    "    \n",
    "    # -------------------------\n",
    "    # üéØ Behavioral data\n",
    "    # -------------------------\n",
    "\n",
    "    choice = trials['choice'][trial_mask]\n",
    "    contrast_row = np.full_like(choice, contrast, dtype=float)\n",
    "    stimLeft = trials['contrastLeft'][trial_mask] # not nan is stim is on the left; nan is stim is on the right\n",
    "    stim_row = np.where(~np.isnan(stimLeft), -1, 1)  # -1 for left, 1 for right\n",
    "    print(stim_row)\n",
    "    behav_matrix = np.vstack([contrast_row, choice, stim_row])  # Shape: (2 x n_trials)\n",
    "\n",
    "    # -------------------------\n",
    "    # üíæ Save to list\n",
    "    # -------------------------\n",
    "    respNeural.append(spike_counts)\n",
    "    respBehav.append(behav_matrix)\n",
    "\n",
    "    print(f\"  ‚úÖ Stored contrast {contrast} | Trials: {len(choice)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52156db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Selected 369 neurons in region CP with quality=False\n",
      "[-1  1 -1 -1  1  1 -1 -1  1  1]\n",
      "  ‚úÖ Stored contrast 0.00 | Trials: 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 63\u001b[0m\n\u001b[1;32m     58\u001b[0m spike_clusters \u001b[38;5;241m=\u001b[39m spikes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclusters\u001b[39m\u001b[38;5;124m'\u001b[39m][is_valid_spike]\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# üìä Spike count matrix\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m spike_counts, used_cluster_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_spike_counts_in_bins\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspike_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspike_clusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_bins\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape: (n_trials, n_neurons)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# üéØ Behavioral data\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[1;32m     70\u001b[0m choice \u001b[38;5;241m=\u001b[39m trials[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoice\u001b[39m\u001b[38;5;124m'\u001b[39m][trial_mask]\n",
      "File \u001b[0;32m~/miniconda3/envs/ibl-env/lib/python3.10/site-packages/brainbox/population/decode.py:20\u001b[0m, in \u001b[0;36mget_spike_counts_in_bins\u001b[0;34m(spike_times, spike_clusters, intervals)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KFold, LeaveOneOut, LeaveOneGroupOut\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_spike_counts_in_bins\u001b[39m(spike_times, spike_clusters, intervals):\n\u001b[1;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    Return the number of spikes in a sequence of time intervals, for each neuron.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m        list of cluster ids\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Check input\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# üéØ Neuron Selection by Region and Quality\n",
    "# ------------------------------------------\n",
    "region_mask = clusters['acronym'] == target_region\n",
    "n_neurons = len(clusters['acronym'])\n",
    "quality_mask = clusters['label'] == 1 if flag_good_quality else np.ones(n_neurons, dtype=bool)\n",
    "valid_cluster_mask = region_mask & quality_mask\n",
    "valid_cluster_ids = clusters['cluster_id'][valid_cluster_mask]\n",
    "\n",
    "print(f\"‚úÖ Selected {len(valid_cluster_ids)} neurons in region {target_region} with quality={flag_good_quality}\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# üóÉÔ∏è Preallocate storage\n",
    "# ------------------------------------------\n",
    "respNeural = []\n",
    "respBehav = []\n",
    "\n",
    "# ------------------------------------------\n",
    "# üîÅ Loop over contrasts\n",
    "# ------------------------------------------\n",
    "for contrast in contrast_levels:\n",
    "\n",
    "    # -------------------------\n",
    "    # üß™ Trial selection (initial mask)\n",
    "    # -------------------------\n",
    "    trial_mask = ((trials['contrastLeft'] == contrast) | (trials['contrastRight'] == contrast)) & \\\n",
    "                 (trials['probabilityLeft'] == prior)\n",
    "\n",
    "    # Reaction time filtering\n",
    "    rt = trials['response_times'] - trials['stimOn_times']\n",
    "    trial_mask &= (rt <= RT_ub) & ~np.isnan(rt)\n",
    "\n",
    "    # Early movement exclusion\n",
    "    movement_latency = trials['firstMovement_times'] - trials['stimOn_times']\n",
    "    no_early_movement_mask = (movement_latency >= window_end) | np.isnan(movement_latency)\n",
    "    trial_mask &= no_early_movement_mask\n",
    "\n",
    "    # Get final valid trial times\n",
    "    valid_trial_times = trials['stimOn_times'][trial_mask]\n",
    "\n",
    "    # if len(valid_trial_times) < nTrials_lb:\n",
    "    #     print(f\"‚ö†Ô∏è Skipping contrast {contrast} due to insufficient trials ({len(valid_trial_times)})\")\n",
    "    #     continue\n",
    "\n",
    "    # -------------------------\n",
    "    # ‚è±Ô∏è Define time bins\n",
    "    # -------------------------\n",
    "    time_bins = np.stack([\n",
    "        valid_trial_times + window_start,\n",
    "        valid_trial_times + window_end\n",
    "    ], axis=1)\n",
    "\n",
    "    # -------------------------\n",
    "    # üîç Filter spikes\n",
    "    # -------------------------\n",
    "    is_valid_spike = np.isin(spikes['clusters'], valid_cluster_ids)\n",
    "    spike_times = spikes['times'][is_valid_spike]\n",
    "    spike_clusters = spikes['clusters'][is_valid_spike]\n",
    "\n",
    "    # -------------------------\n",
    "    # üìä Spike count matrix\n",
    "    # -------------------------\n",
    "    spike_counts, used_cluster_ids = get_spike_counts_in_bins(\n",
    "        spike_times, spike_clusters, time_bins\n",
    "    )  # shape: (n_trials, n_neurons)\n",
    "\n",
    "    # -------------------------\n",
    "    # üéØ Behavioral data\n",
    "    # -------------------------\n",
    "    choice = trials['choice'][trial_mask]\n",
    "    contrast_row = np.full_like(choice, contrast, dtype=float)\n",
    "    stimLeft = trials['contrastLeft'][trial_mask]\n",
    "    stim_row = np.where(~np.isnan(stimLeft), -1, 1)\n",
    "    print(stim_row)\n",
    "    behav_matrix = np.vstack([contrast_row, choice, stim_row])  # shape: (3, n_trials)\n",
    "\n",
    "    # -------------------------\n",
    "    # üíæ Save results\n",
    "    # -------------------------\n",
    "    respNeural.append(spike_counts)\n",
    "    respBehav.append(behav_matrix)\n",
    "\n",
    "    print(f\"  ‚úÖ Stored contrast {contrast:.2f} | Trials: {len(choice)}\")\n",
    "\n",
    "print('===== ‚úÖ ALL DONE =====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4579590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved to data_CP_bias0.5_QCTrue.mat\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "# Convert list of arrays to dtype=object arrays so MATLAB sees them as cells\n",
    "respNeural_cell = np.empty(len(respNeural), dtype=object)\n",
    "respBehav_cell = np.empty(len(respBehav), dtype=object)\n",
    "\n",
    "for i in range(len(respNeural)):\n",
    "    respNeural_cell[i] = respNeural[i]\n",
    "    respBehav_cell[i] = respBehav[i]\n",
    "\n",
    "# Define file name\n",
    "filename = f\"data_{target_region}_bias{prior}_QC{flag_good_quality}.mat\"\n",
    "\n",
    "# Prepare dictionary for saving\n",
    "save_dict = {\n",
    "    'respNeural': respNeural_cell,\n",
    "    'respBehav': respBehav_cell,\n",
    "    'contrast_levels': np.array(contrast_levels),\n",
    "    'prior': prior,\n",
    "    'region': target_region,\n",
    "    'good_quality': flag_good_quality\n",
    "}\n",
    "\n",
    "# Save to .mat file\n",
    "sio.savemat(filename, save_dict)\n",
    "\n",
    "print(f\"‚úÖ Saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc4d95b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
