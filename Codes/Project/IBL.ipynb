{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Required environment: Python 3.10 or more\n",
    "\n",
    "# # üß∞ Install required packages (run this cell only once per environment setup)\n",
    "# # Install the core IBL tools: ONE-api (data access), ibllib (IBL tools),\n",
    "# !pip install ONE-api ibllib \n",
    "\n",
    "# # Install brainbox (analysis utilities)\n",
    "# !pip install git+https://github.com/int-brain-lab/ibllib.git\n",
    "\n",
    "# # Install the scientific and plotting libraries\n",
    "# !pip install matplotlib seaborn pandas numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17f52b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/xueshutian/Downloads/ONE/openalyx.internationalbrainlab.org\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import scipy.io as sio  # For saving\n",
    "\n",
    "# For clearing cache\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "from one.api import ONE\n",
    "from brainbox.io.one import SpikeSortingLoader, SessionLoader\n",
    "from brainbox.behavior.training import compute_performance\n",
    "from brainbox.population.decode import get_spike_counts_in_bins\n",
    "\n",
    "# Connect to IBL data server\n",
    "one = ONE(base_url='https://openalyx.internationalbrainlab.org')\n",
    "print(one.cache_dir)\n",
    "\n",
    "# =========================================\n",
    "# üîÅ Loop through contrast √ó prior settings\n",
    "# =========================================\n",
    "# Spike count window settings\n",
    "window_start = 0          # in seconds\n",
    "window_end = 300 / 1000   # in seconds\n",
    "\n",
    "nNeurons_lb = 10\n",
    "nTrials_lb = 20\n",
    "nTrials_lb = 2\n",
    "RT_ub = 2000 # trials with RT more than this dur (in ms) will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54e86016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid: bf591043-03c2-48bb-9197-e17e85aaeb8f, labels: probe00\n",
      "pid: 5458cb27-d065-4626-bcd8-1aa775e1115e, labels: probe01\n"
     ]
    }
   ],
   "source": [
    "# --- Load session ---\n",
    "# Identify eid (id for experiment)\n",
    "eid = '28741f91-c837-4147-939e-918d38d849f2'\n",
    "label = 'probe00'\n",
    "target_region = 'CP'\n",
    "flag_good_quality = False\n",
    "prior = .5\n",
    "\n",
    "session_info = one.get_details(eid)\n",
    "\n",
    "# Identify the corresponding eid (id for experiment)\n",
    "pids, labels = one.eid2pid(eid)\n",
    "\n",
    "for pid, pname in zip(pids, labels):\n",
    "  print(f'pid: {pid}, labels: {pname}')\n",
    "\n",
    "# Load trial info (one.load_object is simpler than SessionLoader)\n",
    "# sl = SessionLoader(one=one, eid=eid)\n",
    "\n",
    "trials = one.load_object(eid, 'trials', collection='alf')\n",
    "\n",
    "# Next step, visualize basic statistics of behavioral data, like accuracy, \n",
    "# performance, contrasts, n_contrasts = compute_performance(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7aaaac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Load trial and probe info\n",
    "# ================================\n",
    "pids, labels = one.eid2pid(eid)\n",
    "trials = one.load_object(eid, 'trials', collection='alf')\n",
    "contrast_levels = np.unique(trials['contrastLeft'])\n",
    "prior_levels = np.unique(trials['probabilityLeft'])\n",
    "\n",
    "# assert that prior_levels has three levels: 0.2, 0.5 and 0.8\n",
    "assert np.array_equal(prior_levels, [0.2, 0.5, 0.8]), f\"Unexpected prior_levels: {prior_levels}\"\n",
    "\n",
    "# ================================\n",
    "# Load spikes and clusters\n",
    "# ================================\n",
    "ssl = SpikeSortingLoader(eid=eid, one=one, pname=label)\n",
    "spikes, clusters, channels = ssl.load_spike_sorting()\n",
    "clusters = ssl.merge_clusters(spikes, clusters, channels)\n",
    "# regions_all = np.unique(clusters['acronym'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502764a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Region: CP     | Quality: False | Neurons: 369\n",
      "  ‚úÖ Contrast: 0.0  | Prior: 0.5 | Trials: 4\n",
      "  ‚úÖ Contrast: 0.0625 | Prior: 0.5 | Trials: 4\n",
      "  ‚úÖ Contrast: 0.125 | Prior: 0.5 | Trials: 7\n",
      "  ‚úÖ Contrast: 0.25 | Prior: 0.5 | Trials: 3\n",
      "  ‚úÖ Contrast: 1.0  | Prior: 0.5 | Trials: 4\n",
      "  ‚úÖ Contrast: nan  | Prior: 0.5 | Trials: 0\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# üß† Select valid neurons\n",
    "# ================================\n",
    "\n",
    "# Create a boolean mask for neurons in the current target brain region\n",
    "region_mask = clusters['acronym'] == target_region\n",
    "\n",
    "# Count total number of neurons in the session\n",
    "n_neurons = len(clusters['acronym'])\n",
    "\n",
    "# Create a boolean mask for neuron quality: \n",
    "# if flag_good_quality is True, select only high-quality neurons (label == 1),\n",
    "# otherwise select all neurons\n",
    "quality_mask = clusters['label'] == 1 if flag_good_quality else np.ones(n_neurons, dtype=bool)\n",
    "\n",
    "# Combine region and quality masks to get neurons that satisfy both criteria\n",
    "valid_cluster_mask = region_mask & quality_mask\n",
    "\n",
    "# Extract the cluster IDs for valid neurons\n",
    "valid_cluster_ids = clusters['cluster_id'][valid_cluster_mask]\n",
    "\n",
    "# Log region info\n",
    "print(f\"üéØ Region: {target_region:<6} | Quality: {flag_good_quality} | Neurons: {len(valid_cluster_ids)}\")\n",
    "\n",
    "# ================================\n",
    "# ‚è± Precompute valid trial masks\n",
    "# ================================\n",
    "\n",
    "# Compute response time (RT) for each trial\n",
    "rt = trials['response_times'] - trials['stimOn_times']\n",
    "\n",
    "# Compute movement latency: time from stimulus onset to first movement\n",
    "movement_latency = trials['firstMovement_times'] - trials['stimOn_times']\n",
    "\n",
    "# Create a mask for trials with valid RT (not too long, and not NaN)\n",
    "valid_rt_mask = (rt <= RT_ub) & ~np.isnan(rt)\n",
    "\n",
    "# Create a mask for trials without early movement (or missing movement time)\n",
    "valid_latency_mask = (movement_latency >= window_end) | np.isnan(movement_latency)\n",
    "\n",
    "# ================================\n",
    "# üß™ Select trials per condition\n",
    "# ================================\n",
    "\n",
    "for contrast in contrast_levels:\n",
    "\n",
    "    # Create a trial mask matching contrast and prior, \n",
    "    # while also applying the precomputed RT and latency masks\n",
    "    trial_mask = (trials['contrastLeft'] == contrast) & \\\n",
    "                    (trials['probabilityLeft'] == prior) & \\\n",
    "                    valid_rt_mask & valid_latency_mask\n",
    "\n",
    "    # Get the stimulus onset times for valid trials\n",
    "    valid_trial_times = trials['stimOn_times'][trial_mask]\n",
    "\n",
    "    # Log the number of valid trials for this condition\n",
    "    print(f\"  ‚úÖ Contrast: {contrast:<4} | Prior: {prior} | Trials: {len(valid_trial_times)}\")\n",
    "\n",
    "    # Calculate spike counts\n",
    "    spike_counts, cluster_ids = get_spike_counts_in_bins(\n",
    "        spikes,\n",
    "        valid_trial_times,\n",
    "        cluster_ids=valid_cluster_ids,\n",
    "        bin_size=(window_end - window_start),\n",
    "        start_time=window_start,\n",
    "        end_time=window_end\n",
    "    )\n",
    "    # Behavioral response: (1 x n_trials)\n",
    "    choice = trials['choice'][trial_mask]\n",
    "    choice = ((choice + 1) // 2).astype(int)\n",
    "\n",
    "    # Contrast row: same length as behavior\n",
    "    contrast_row = np.full_like(choice, contrast, dtype=float)\n",
    "\n",
    "    # Stack into 2√ón_trials matrix\n",
    "    behav_matrix = np.vstack([contrast_row, choice])\n",
    "\n",
    "    # Append\n",
    "    respNeural.append(spike_counts)\n",
    "    respBehav.append(behav_matrix)\n",
    "\n",
    "    print(f\"  ‚úÖ Stored contrast {contrast} | Trials: {len(choice)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7231a9f",
   "metadata": {},
   "source": [
    "## Save respNeural and respBehav to .mat files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52156db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Stored contrast 0.0 | Trials: 4\n",
      "  ‚úÖ Stored contrast 0.0625 | Trials: 4\n",
      "  ‚úÖ Stored contrast 0.125 | Trials: 7\n",
      "  ‚úÖ Stored contrast 0.25 | Trials: 3\n",
      "  ‚úÖ Stored contrast 1.0 | Trials: 4\n",
      "===== ALL DONE ====\n"
     ]
    }
   ],
   "source": [
    "# Preallocate \n",
    "respNeural = []  # List to store spike counts\n",
    "respBehav = []  # List to store behavioral data\n",
    "\n",
    "# =========================\n",
    "# üîÅ Loop over contrasts\n",
    "# =========================\n",
    "for contrast in contrast_levels:\n",
    "    \n",
    "    # -------------------------\n",
    "    # üß™ Trial selection\n",
    "    # -------------------------\n",
    "    trial_mask = (trials['contrastLeft'] == contrast) & \\\n",
    "                 (trials['probabilityLeft'] == prior) & \\\n",
    "                 valid_rt_mask & valid_latency_mask\n",
    "    valid_trial_times = trials['stimOn_times'][trial_mask]\n",
    "\n",
    "    if len(valid_trial_times) < nTrials_lb:\n",
    "        continue\n",
    "\n",
    "    # -------------------------\n",
    "    # ‚è±Ô∏è Define time bins per trial\n",
    "    # -------------------------\n",
    "    time_bins = np.stack([\n",
    "        valid_trial_times + window_start,\n",
    "        valid_trial_times + window_end\n",
    "    ], axis=1)\n",
    "\n",
    "    # -------------------------\n",
    "    # üîç Spike filtering\n",
    "    # -------------------------\n",
    "    is_valid_spike = np.isin(spikes['clusters'], valid_cluster_ids)\n",
    "    spike_times = spikes['times'][is_valid_spike]\n",
    "    spike_clusters = spikes['clusters'][is_valid_spike]\n",
    "\n",
    "    # -------------------------\n",
    "    # üìä Spike count matrix\n",
    "    # -------------------------\n",
    "    spike_counts, used_cluster_ids = get_spike_counts_in_bins(\n",
    "        spike_times, spike_clusters, time_bins\n",
    "    )  # Output: (n_trials x n_neurons)\n",
    "    \n",
    "    spike_counts = spike_counts.T  # ‚Üí (n_neurons x n_trials)\n",
    "\n",
    "    # -------------------------\n",
    "    # üéØ Behavioral data\n",
    "    # -------------------------\n",
    "    choice = trials['choice'][trial_mask]\n",
    "    contrast_row = np.full_like(choice, contrast, dtype=float)\n",
    "    behav_matrix = np.vstack([contrast_row, choice])  # Shape: (2 x n_trials)\n",
    "\n",
    "    # -------------------------\n",
    "    # üíæ Save to list\n",
    "    # -------------------------\n",
    "    respNeural.append(spike_counts)\n",
    "    respBehav.append(behav_matrix)\n",
    "\n",
    "    print(f\"  ‚úÖ Stored contrast {contrast} | Trials: {len(choice)}\")\n",
    "\n",
    "print('===== ALL DONE ====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4579590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved to data_CP_bias0.5_N819.mat\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "# Convert list of arrays to dtype=object arrays so MATLAB sees them as cells\n",
    "respNeural_cell = np.empty(len(respNeural), dtype=object)\n",
    "respBehav_cell = np.empty(len(respBehav), dtype=object)\n",
    "\n",
    "for i in range(len(respNeural)):\n",
    "    respNeural_cell[i] = respNeural[i]\n",
    "    respBehav_cell[i] = respBehav[i]\n",
    "\n",
    "# Define file name\n",
    "filename = f\"data_{target_region}_bias{prior}_N{n_neurons}.mat\"\n",
    "\n",
    "# Prepare dictionary for saving\n",
    "save_dict = {\n",
    "    'respNeural': respNeural_cell,\n",
    "    'respBehav': respBehav_cell,\n",
    "    'contrast_levels': np.array(contrast_levels),\n",
    "    'prior': prior,\n",
    "    'region': target_region,\n",
    "    'good_quality': flag_good_quality\n",
    "}\n",
    "\n",
    "# Save to .mat file\n",
    "sio.savemat(filename, save_dict)\n",
    "\n",
    "print(f\"‚úÖ Saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e025cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine contrastLeft and contrastRight into one array and drop NaNs\n",
    "all_contrasts = np.concatenate([\n",
    "    trials['contrastLeft'][~np.isnan(trials['contrastLeft'])],\n",
    "    trials['contrastRight'][~np.isnan(trials['contrastRight'])]\n",
    "])\n",
    "\n",
    "unique_contrasts = np.unique(all_contrasts)\n",
    "print(\"Unique target contrasts:\", unique_contrasts)\n",
    "print(\"Number of unique contrasts:\", len(unique_contrasts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219bcccb",
   "metadata": {},
   "source": [
    "## Load the condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e669dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# üß† Filtering Setup\n",
    "# =========================\n",
    "\n",
    "target_region = 'LP'        # Brain region of interest\n",
    "target_contrast = 0.0     # Contrast level of interest (valid: [0, 0.0625, 0.125, 0.25, 1])\n",
    "target_prior = 0.5          # Prior probability of stimulus being on the LEFT side\n",
    "# (0.8 = left-biased, 0.2 = right-biased, 0.5 = neutral)\n",
    "flag_good_quality = False   # Whether to include only good-quality neurons\n",
    "\n",
    "# Spike count window (relative to stimulus onset)\n",
    "window_start = 0          # in seconds (100 ms)\n",
    "window_end = 300/1000            # in seconds (200 ms)\n",
    "dd\n",
    "# Format prior label for naming/saving purposes\n",
    "prior_label = {\n",
    "    0.2: 'RightBiased',\n",
    "    0.5: 'Neutral',\n",
    "    0.8: 'LeftBiased'\n",
    "}.get(target_prior, f\"P{int(target_prior * 100)}\")\n",
    "\n",
    "# =========================\n",
    "# üß™ Neuron Selection\n",
    "# =========================\n",
    "\n",
    "region_mask = clusters['acronym'] == target_region\n",
    "n_neurons = len(clusters['acronym'])\n",
    "\n",
    "quality_mask = clusters['label'] == 1 if flag_good_quality else np.ones(n_neurons, dtype=bool)\n",
    "valid_cluster_mask = region_mask & quality_mask\n",
    "valid_cluster_ids = clusters['cluster_id'][valid_cluster_mask]\n",
    "\n",
    "print(f\"# Neurons in {target_region}: {len(valid_cluster_ids)}\")\n",
    "\n",
    "# =========================\n",
    "# üß™ Trial Selection\n",
    "# =========================\n",
    "\n",
    "trial_mask = (trials['contrastLeft'] == target_contrast) & \\\n",
    "             (trials['probabilityLeft'] == target_prior)\n",
    "\n",
    "movement_latency = trials['firstMovement_times'] - trials['stimOn_times']\n",
    "no_early_movement_mask = (movement_latency >= window_end) | np.isnan(movement_latency)\n",
    "\n",
    "trial_mask &= no_early_movement_mask\n",
    "valid_trial_times = trials['stimOn_times'][trial_mask]\n",
    "\n",
    "print(f\"# Valid trials after filtering: {len(valid_trial_times)}\")\n",
    "\n",
    "# =========================\n",
    "# ‚è±Ô∏è Define Spike Count Window\n",
    "# =========================\n",
    "\n",
    "time_bins = np.stack([\n",
    "    valid_trial_times + window_start,\n",
    "    valid_trial_times + window_end\n",
    "], axis=1)\n",
    "\n",
    "# =========================\n",
    "# üîç Spike Filtering\n",
    "# =========================\n",
    "\n",
    "is_valid_spike = np.isin(spikes.clusters, valid_cluster_ids)\n",
    "spike_times = spikes.times[is_valid_spike]\n",
    "spike_clusters = spikes.clusters[is_valid_spike]\n",
    "\n",
    "# =========================\n",
    "# üìä Spike Count Computation\n",
    "# =========================\n",
    "\n",
    "spike_counts, all_cluster_ids = get_spike_counts_in_bins(\n",
    "    spike_times, spike_clusters, time_bins\n",
    ")\n",
    "print(\"Spike count matrix shape (nNeurons √ó nTrials):\", spike_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595fdb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualize ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(spike_counts, cmap='viridis', cbar_kws={'label': 'Spike Count'})\n",
    "plt.xlabel(\"Trial\")\n",
    "plt.ylabel(\"Neuron\")\n",
    "plt.title(f\"Spike counts (100‚Äì200ms post-stimulus) ‚Äî {target_region}, contrast {target_contrast}, prior {target_prior}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3865720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data snippet in .mat format\n",
    "# Format contrast as two-digit string\n",
    "contrast_str = f\"{int(target_contrast * 100):02d}\"\n",
    "\n",
    "# Get matrix shape: neurons √ó trials\n",
    "n_neurons, n_trials = spike_counts.shape\n",
    "\n",
    "# Construct filename\n",
    "filename = f\"spikeCount_{target_region}_C{contrast_str}_bias{prior_label}_N{n_neurons}_T{n_trials}.mat\"\n",
    "\n",
    "# Save to .mat file (MATLAB-compatible)\n",
    "sio.savemat(filename, {'spike_counts': spike_counts})\n",
    "\n",
    "print(f\"Saved spike count matrix to MATLAB file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# üéØ Extract Behavioral Responses\n",
    "# =========================\n",
    "# Use previously defined trial_mask (includes contrast, prior, and movement filtering)\n",
    "behavior_responses = trials['choice'][trial_mask]  # shape: (n_trials,)\n",
    "\n",
    "# --- Inspect response distribution ---\n",
    "print(\"Behavior responses shape:\", behavior_responses.shape)\n",
    "print(\"Unique responses:\", np.unique(behavior_responses))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(behavior_responses, bins=np.arange(-1.5, 2.5, 1), rwidth=0.8)\n",
    "plt.xticks([0, -1, 1], labels=['No Go', 'Left', 'Right'])\n",
    "plt.xlabel(\"Choice\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Behavioral Choices on Selected Trials\")\n",
    "# Print the parameters in the title\n",
    "plt.title(f\"Region: {target_region}, Contrast: {target_contrast}, Prior: {target_prior}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# üíæ Save to .mat file\n",
    "# =========================\n",
    "\n",
    "# Optional: dynamic filename using condition labels\n",
    "contrast_str = f\"{int(target_contrast * 100):02d}\"  # e.g., \"12\" for 0.125\n",
    "filename = f\"behavior_LP_C{contrast_str}_{prior_label}.mat\"\n",
    "\n",
    "sio.savemat(filename, {\"behavior_responses\": behavior_responses})\n",
    "print(f\"Behavior responses saved to: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
